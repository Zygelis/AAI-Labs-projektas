{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9408b90-76c0-4317-886d-7401b78f2036",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Data_preparation_6'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(new_directory)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# We can import file modules after changing working directory\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mData_preparation_6\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipynb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mModels_6\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Determine the best model overall\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# This usually takes a few minutes to run. The best model is LGBM.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#best_model = compare_models(df_X, df_y)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# If you want to run code faster, comment out the line above and uncomment the line below.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Data_preparation_6'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Change working directory for jupyter\n",
    "new_directory = \"C:\\\\Users\\\\Zygis\\\\Desktop\\\\AAI-Labs-projektas\"\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# We can import file modules after changing working directory\n",
    "from Data_preparation_6 import *\n",
    "from Models_6 import *\n",
    "\n",
    "\n",
    "# Determine the best model overall\n",
    "# This usually takes a few minutes to run. The best model is LGBM.\n",
    "#best_model = compare_models(df_X, df_y)\n",
    "# If you want to run code faster, comment out the line above and uncomment the line below.\n",
    "best_model = model_lgbm\n",
    "\n",
    "# Best model prediction\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "\n",
    "# Prediction error on the training and the testing data sets for the best model\n",
    "print(\"\\n\")\n",
    "print('A)')\n",
    "print(\"Prediction error on the training and the testing data sets for the best model with all features:\")\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "print(\"mae_test:\", mae_test)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "print(\"mse_test:\", mse_test)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "print(\"mae_train:\", mae_train)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "print(\"mse_train:\", mse_train)\n",
    "\n",
    "\n",
    "# Fields used in the model (all_features)\n",
    "print(\"\\n\")\n",
    "print('B)')\n",
    "print(\"Fields used in the model:\")\n",
    "print(all_features)\n",
    "\n",
    "\n",
    "# Top 5 fields/features that contribute the most to the predictions\n",
    "mi_scores = make_mi_scores(df_X, df_y)\n",
    "top_5_features = mi_scores.head(5)\n",
    "print(\"\\n\")\n",
    "print('C)')\n",
    "print(\"Top 5 fields/features that contribute the most to the predictions:\")\n",
    "print(top_5_features)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Make top 5 features codes a list\n",
    "top_5_features = top_5_features.index.tolist()\n",
    "\n",
    "# Add NGDPDPC to top_5_features as a target\n",
    "top_5_features.append(\"NGDPDPC\")\n",
    "\n",
    "# Train another predictor that uses those top 5 features\n",
    "# Prepare data\n",
    "df_X_top5, df_y_top5 = data_preparation(df, top_5_features)\n",
    "\n",
    "# Split data\n",
    "X_train_top5, X_test_top5, y_train_top5, y_test_top5 = train_test_split(df_X_top5, df_y_top5, random_state=0)\n",
    "\n",
    "# Train another predictor that uses those top 5 features\n",
    "model_top5 = LGBM_model_fit(X_train_top5, y_train_top5)\n",
    "\n",
    "# Best model prediction\n",
    "y_test_pred_top5 = model_top5.predict(X_test_top5)\n",
    "y_train_pred_top5 = model_top5.predict(X_train_top5)\n",
    "\n",
    "# Prediction error on the training and the testing data sets\n",
    "print(\"\\n\")\n",
    "print('D)')\n",
    "print(\"Prediction error on the training and the testing data sets with top 5 features\")\n",
    "mae_test_top5 = mean_absolute_error(y_test_top5, y_test_pred_top5)\n",
    "print(\"mae_test:\", mae_test_top5)\n",
    "mse_test_top5 = mean_squared_error(y_test_top5, y_test_pred_top5)\n",
    "print(\"mse_test:\", mse_test_top5)\n",
    "mae_train_top5 = mean_absolute_error(y_train_top5, y_train_pred_top5)\n",
    "print(\"mae_train:\", mae_train_top5)\n",
    "mse_train_top5 = mean_squared_error(y_train_top5, y_train_pred_top5)\n",
    "print(\"mse_train:\", mse_train_top5)\n",
    "\n",
    "\n",
    "# Save the model\n",
    "print(\"\\n\")\n",
    "print('E)')\n",
    "print(\"Saved the model as:\")\n",
    "print(\"model_top5.joblib\")\n",
    "print(\"\\n\")\n",
    "\n",
    "save_path = \"6-dalis\\\\model_top5.joblib\"\n",
    "joblib.dump(model_top5, save_path)\n",
    "\n",
    "# Load the model\n",
    "model_loaded = joblib.load(\"6-dalis\\\\model_top5.joblib\")\n",
    "\n",
    "\n",
    "# Predictor with best MAE and MSE scores that I have found:\n",
    "# Features used in the model\n",
    "features_min_error = ['NGDPDPC', 'BCA', 'LP', 'LUR', 'GGXWDG', 'GGX', 'GGR', 'PPPEX', 'GGXCNL']\n",
    "\n",
    "# Prepare data\n",
    "df_X, df_y = data_preparation(df, features_min_error)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, random_state=0)\n",
    "\n",
    "# Train model\n",
    "model_min_error = LGBM_model_fit(X_train, y_train)\n",
    "\n",
    "# Predictions for test and train data\n",
    "y_test_pred_min_error = model_min_error.predict(X_test)\n",
    "y_train_pred_min_error = model_min_error.predict(X_train)\n",
    "\n",
    "# Prediction error\n",
    "mae_test_min_error = mean_absolute_error(y_test, y_test_pred_min_error)\n",
    "mse_test_min_error = mean_squared_error(y_test, y_test_pred_min_error)\n",
    "mae_train_min_error = mean_absolute_error(y_train, y_train_pred_min_error)\n",
    "mse_train_min_error = mean_squared_error(y_train, y_train_pred_min_error)\n",
    "\n",
    "print(\"\\n\")\n",
    "print('F)')\n",
    "print(\"Prediction error on the training and the testing data sets for the best model with minimum error:\")\n",
    "print(\"mae_test:\", mae_test_min_error)\n",
    "print(\"mse_test:\", mse_test_min_error)\n",
    "print(\"mae_train:\", mae_train_min_error)\n",
    "print(\"mse_train:\", mse_train_min_error)\n",
    "print(\"\\n\")\n",
    "print(\"Fields used in the model with minimum error:\")\n",
    "print(features_min_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d31592-c77f-4ea3-8d66-1b288f550e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
