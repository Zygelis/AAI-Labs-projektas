{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab22b47e-785f-444c-8cb5-85565c82073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_Data_preparation.py done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Change working directory for jupyter\n",
    "new_directory = \"C:\\\\Users\\\\Zygis\\\\Desktop\\\\AAI-Labs-projektas\"\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Read data\n",
    "df = pd.read_excel(\"WEOOct2020all.xls\", engine=\"xlrd\")\n",
    "\n",
    "# Features that are not related to GDP per capita, except 'NGDPDPC' which is the target variable.\n",
    "all_features = [\n",
    "    \"NGDPDPC\",\n",
    "    \"PPPEX\",\n",
    "    \"PCPI\",\n",
    "    \"PCPIE\",\n",
    "    \"TM_RPCH\",\n",
    "    \"TMG_RPCH\",\n",
    "    \"TX_RPCH\",\n",
    "    \"TXG_RPCH\",\n",
    "    \"LUR\",\n",
    "    \"LE\",\n",
    "    \"LP\",\n",
    "    \"GGR\",\n",
    "    \"GGX\",\n",
    "    \"GGXCNL\",\n",
    "    \"GGSB\",\n",
    "    \"GGXONLB\",\n",
    "    \"GGXWDN\",\n",
    "    \"GGXWDG\",\n",
    "    \"BCA\",\n",
    "]\n",
    "\n",
    "\n",
    "# Data preparation\n",
    "def data_preparation(df, features):\n",
    "    df = df.drop(\n",
    "        [\n",
    "            \"Country\",\n",
    "            \"Subject Descriptor\",\n",
    "            \"Units\",\n",
    "            \"Subject Notes\",\n",
    "            \"Country/Series-specific Notes\",\n",
    "            \"Estimates Start After\",\n",
    "            \"Scale\",\n",
    "            \"ISO\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Clean strange values that could corrupt data\n",
    "    df = (\n",
    "        df.replace(\"\\n\", np.nan)\n",
    "        .replace(\"\\t\", np.nan)\n",
    "        .replace(\";\", np.nan)\n",
    "        .replace(\"--\", np.nan)\n",
    "    )\n",
    "\n",
    "    # Select rows where WEO Subject Code is features\n",
    "    df = df[df[\"WEO Subject Code\"].isin(features)]\n",
    "\n",
    "    # MODIFYING DATAFRAME STRUCTURE\n",
    "    # Use melt to move years to a single column\n",
    "    df_melted = df.melt(\n",
    "        id_vars=[\"WEO Country Code\", \"WEO Subject Code\"],\n",
    "        var_name=\"Year\",\n",
    "        value_name=\"Value\",\n",
    "    )\n",
    "\n",
    "    # Use pivot to make each feature a column\n",
    "    df_pivoted = df_melted.pivot_table(\n",
    "        index=[\"WEO Country Code\", \"Year\"],\n",
    "        columns=\"WEO Subject Code\",\n",
    "        values=\"Value\",\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "\n",
    "    # Reset the index to return index to columns\n",
    "    df_pivoted.reset_index(inplace=True)\n",
    "\n",
    "    # DEALING WITH NAN VALUES\n",
    "    # Drop column if more then 40% values are nan\n",
    "    df_pivoted = df_pivoted.dropna(axis=1, thresh=int(len(df_pivoted) * 0.5))\n",
    "\n",
    "    # Drop row if more then 40% values are nan\n",
    "    df_pivoted = df_pivoted.dropna(axis=0, thresh=int(len(df_pivoted.columns) * 0.5))\n",
    "\n",
    "    # Fill nan values with mean of collumn\n",
    "    df_pivoted = df_pivoted.fillna(df_pivoted.mean())\n",
    "\n",
    "    # Now we have clean data\n",
    "    # Drop \"WEO Country Code\", \"Year\" because they are not needed\n",
    "    df_pivoted = df_pivoted.drop([\"WEO Country Code\", \"Year\"], axis=1)\n",
    "\n",
    "    # To excel\n",
    "    #df_pivoted.to_excel(\"df_cleaned.xlsx\")\n",
    "\n",
    "    # Split data to X and y\n",
    "    df_X = df_pivoted.drop([\"NGDPDPC\"], axis=1)\n",
    "\n",
    "    df_y = df_pivoted[\"NGDPDPC\"]\n",
    "\n",
    "    return df_X, df_y\n",
    "\n",
    "\n",
    "def data_split(df_X, df_y):\n",
    "    # Split data to train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def data_scale(df_X):\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_X)\n",
    "\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "# Feature selection (mutual information)\n",
    "def make_mi_scores(X, y):\n",
    "    # Create discrete features for mutual information calculation\n",
    "    discrete_features = X.dtypes == int\n",
    "\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(mi_scores):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    ax = sns.barplot(x=mi_scores, y=mi_scores.index)\n",
    "    ax.set_title(\"Mutual Information Scores\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df_X, df_y = data_preparation(df, all_features)\n",
    "\n",
    "mi_scores = make_mi_scores(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(df_X, df_y)\n",
    "\n",
    "print(\"6_Data_preparation.py done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26916b0a-6eeb-44c0-9371-8fdc58c2e5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
