{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41e30b39-6681-4ac6-a6da-5c20b5b55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 5891, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 10189.517567\n",
      "\n",
      "\n",
      "Models_6.py done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "\n",
    "# Change working directory for jupyter\n",
    "new_directory = \"C:\\\\Users\\\\Zygis\\\\Desktop\\\\AAI-Labs-projektas\"\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# We can import file module after changing working directory\n",
    "from Data_preparation_6 import *\n",
    "\n",
    "# Read data\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\Zygis\\\\Desktop\\\\test\\\\WEOOct2020all.xls\", engine=\"xlrd\")\n",
    "\n",
    "# Prepare data\n",
    "df_X, df_y = data_preparation(df, all_features)\n",
    "\n",
    "# Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, random_state=0)\n",
    "\n",
    "\n",
    "# Define 3 models:\n",
    "# XGBoost model\n",
    "def XGB_model_fit(X_train, y_train, X_test, y_test):\n",
    "    # Train model\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=1000, learning_rate=0.05, n_jobs=4, random_state=0\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        early_stopping_rounds=10,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# LightGBM model\n",
    "def LGBM_model_fit(X_train, y_train):\n",
    "    # Train model\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=1000, learning_rate=0.05, n_jobs=4, random_state=0\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Random Forest model\n",
    "def RF_model_fit(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    # Select categorical columns with low unique values\n",
    "    categorical_cols = [\n",
    "        cname\n",
    "        for cname in X_train.columns\n",
    "        if X_train[cname].nunique() < 10 and X_train[cname].dtype == \"object\"\n",
    "    ]\n",
    "\n",
    "    # Select numerical columns\n",
    "    numerical_cols = [\n",
    "        cname\n",
    "        for cname in X_train.columns\n",
    "        if X_train[cname].dtype in [\"int64\", \"float64\"]\n",
    "    ]\n",
    "\n",
    "    # Keep selected columns only\n",
    "    my_cols = categorical_cols + numerical_cols\n",
    "    X_train = X_train[my_cols].copy()\n",
    "    X_test = X_test[my_cols].copy()\n",
    "\n",
    "    # Preprocessing for numerical data\n",
    "    numerical_transformer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create one preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, numerical_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define model\n",
    "    model = RandomForestRegressor(n_estimators=900, random_state=0, n_jobs=4)\n",
    "\n",
    "    # Create pipeline with preprocessor and ML model\n",
    "    RF_pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    RF_pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Get predictions\n",
    "    prediction = RF_pipe.predict(X_test)\n",
    "\n",
    "    return RF_pipe\n",
    "\n",
    "\n",
    "# Fit and define models\n",
    "model_xgb = XGB_model_fit(X_train, y_train, X_test, y_test)\n",
    "model_lgbm = LGBM_model_fit(X_train, y_train)\n",
    "model_rf = RF_model_fit(df_X, df_y)\n",
    "\n",
    "\n",
    "# Model quality evaluation\n",
    "def perform_cross_validation(model, X, y, num_folds=5):\n",
    "    # Initialize KFold cross-validator\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    # Perform cross-validation and calculate MAE and MSE scores\n",
    "    scores_mae = -1 * cross_val_score(\n",
    "        model, X, y, cv=kf, scoring=\"neg_mean_absolute_error\"\n",
    "    )  # Multiply by -1 to Convert back to positive\n",
    "\n",
    "    scores_mse = -1 * cross_val_score(\n",
    "        model, X, y, cv=kf, scoring=\"neg_mean_squared_error\"\n",
    "    )  # Multiply by -1 to Convert back to positive4\n",
    "\n",
    "    # Calculate the mean of MAE and MSE scores\n",
    "    mean_mae = scores_mae.mean()\n",
    "\n",
    "    mean_mse = scores_mse.mean()\n",
    "\n",
    "    return mean_mae, mean_mse\n",
    "\n",
    "\n",
    "# Compare models and select the best one\n",
    "def compare_models(X, y):\n",
    "    models = {\"XGB\": model_xgb, \"LGBM\": model_lgbm, \"RF\": model_rf}\n",
    "\n",
    "    results_mae = {}\n",
    "    results_mse = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        mean_mae, mean_mse = perform_cross_validation(model, X, y)\n",
    "        results_mae[name] = mean_mae\n",
    "        results_mse[name] = mean_mse\n",
    "\n",
    "    best_model_mae = min(results_mae, key=results_mae.get)\n",
    "    best_model_mse = min(results_mse, key=results_mse.get)\n",
    "\n",
    "    print(\"\\n\" * 2)\n",
    "    print(\"Model comparison results:\")\n",
    "\n",
    "    for name, mae_score in results_mae.items():\n",
    "        mse_score = results_mse[name]\n",
    "        print(f\"{name}: MAE = {mae_score:.4f}, MSE = {mse_score:.4f}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\n",
    "        f\"Best model based on MAE: {best_model_mae} with MAE = {results_mae[best_model_mae]:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Best model based on MSE: {best_model_mse} with MSE = {results_mse[best_model_mse]:.4f}\"\n",
    "    )\n",
    "\n",
    "    return models[best_model_mse]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Models_6.py done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d72d3-771e-4f0c-90d4-225596e08510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
